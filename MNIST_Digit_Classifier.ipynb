{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Digit Classifier ",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jvr2pi-UqW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import the required libraries from PyTorch(Deep Learning Framework), and pyplot for aided visualization \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.cuda as cuda\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CdqMHUIVP2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define some basic transformer operations to properly prepare the images\n",
        "mean = 0.1307 \n",
        "std = 0.3081\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean,), (std,))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FgylXd9Xm85",
        "colab_type": "code",
        "outputId": "736cc05c-97fb-4810-ec8a-259c0ea60b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "#Load the MNIST dataset from torchvision\n",
        "\n",
        "train_set = datasets.MNIST('/data', train=True, transform=transform, download=True)\n",
        "test_set = datasets.MNIST('/data', train=False, transform=transform, download=True )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8379089.10it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 85483.31it/s]            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:01, 1077367.27it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 26367.27it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT4NvKNwYJ0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feed the dataset into the dataloaders\n",
        "\n",
        "batch_size=1200\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sueCGX3luef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classes for which we want to classify our images into\n",
        "classes = ('one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine',)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_EBcbA5mUSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to show an image in order to get a better understanding of the data\n",
        "\n",
        "def imshow(img):\n",
        "  img = img * std + mean #unnormalize the data\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(npimg.reshape(28, 28), cmap='gray')\n",
        "  plt.show()  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ccUEnTnyUM",
        "colab_type": "code",
        "outputId": "f6f6d1b3-6f47-48ea-fe27-cd226498ae9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#function call to display image, change the first index to see the other images in dataset. There are 60,000 images in this dataset\n",
        "image = train_set[0][0]\n",
        "imshow(image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4AEJj2JODq_",
        "colab_type": "text"
      },
      "source": [
        "# Size of Output Activation Map Fromula \n",
        "\n",
        "![alt text](https://miro.medium.com/max/413/0*_r70kZaBlXSyZzz5.)\n",
        "\n",
        "**function to make sure you are properly layering neural network**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z02GDbodcK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the Convoluted Neural Network\n",
        "\n",
        "#Note: by default padding = 0, stride = 1\n",
        "\n",
        "class Net(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    #Convulation Layer #1                                             # 28 x 28 x 1 (input)\n",
        "    self.conv1 = nn.Conv2d(1, 20, kernel_size=5)                      # 24 x 24 x 20 (first convolution)\n",
        "    self.rel1 = nn.ReLU()                                             # activation function\n",
        "\n",
        "    #Convulation Layer #2\n",
        "    self.conv2 = nn.Conv2d(20, 40, kernel_size=5)                     # 24 x 24 x 30 (input)\n",
        "    self.conv2_drop = nn.Dropout(p=0.5)                               # 20 x 20 x 40 (second convultion)\n",
        "    self.pool = nn.MaxPool2d(2)                                       # 10 x 10 x 40 (pooling)\n",
        "    self.rel2 = nn.ReLU()                                             # activation function\n",
        "\n",
        "    #Fully Connecting Layers\n",
        "    self.lin1 = nn.Linear(4000, 500)                                  # 10 * 10 * 40 = 4000 (input)\n",
        "    self.lin2 = nn.Linear(500, 10)                                    # 500 ---- > 10 (our handwritten digits 0-9)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    #Convluation Layer #1\n",
        "    x = self.conv1(x)\n",
        "    x = self.rel1(x)\n",
        "      \n",
        "    #Convulation Layer #2\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv2_drop(x)      \n",
        "    x = self.pool(x)\n",
        "    x = self.rel2(x)\n",
        "\n",
        "    #switch from activation map to vector so that we can pass into linear layers\n",
        "    x = x.view(-1, 4000)\n",
        "\n",
        "    #Fully Connecting Layers\n",
        "    x = self.lin1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, training=True)\n",
        "\n",
        "    x = self.lin2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBv6pghwXCih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#create model object\n",
        "model = Net()\n",
        "model = model.to(device)\n",
        "\n",
        "#loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#create optimizer object\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWlCVPdT_YOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training Function\n",
        "\n",
        "def train(num_epoch):\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(num_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "      \n",
        "      #get the inputs and move tensors to GPU\n",
        "      images, digits = data\n",
        "      images = images.to(device)\n",
        "      digits = digits.to(device)\n",
        "\n",
        "      #zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      #forward pass + backpropagation + optimize\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, digits)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      #print statistics\n",
        "      running_loss += loss\n",
        "\n",
        "      if i % 10 == 9:\n",
        "        print(f'[Epoch: {epoch+1}, {i+1} / {len(train_loader)}] loss: {running_loss/2000}')\n",
        "\n",
        "        running_loss = 0.0\n",
        "  \n",
        "  print(\"Finished Training\")\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sepRtvupeZoM",
        "colab_type": "code",
        "outputId": "7fbbf6fb-9e5e-4de5-82a8-49b38623a20e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "#train the model through however many epochs. In this case, we use 10 epochs and observe the loss\n",
        "train(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch: 1, 10 / 50] loss: 0.01044540572911501\n",
            "[Epoch: 1, 20 / 50] loss: 0.0045465524308383465\n",
            "[Epoch: 1, 30 / 50] loss: 0.0026129460893571377\n",
            "[Epoch: 1, 40 / 50] loss: 0.002040607389062643\n",
            "[Epoch: 1, 50 / 50] loss: 0.0016026862431317568\n",
            "[Epoch: 2, 10 / 50] loss: 0.0013502842048183084\n",
            "[Epoch: 2, 20 / 50] loss: 0.0012623484944924712\n",
            "[Epoch: 2, 30 / 50] loss: 0.0011543974978849292\n",
            "[Epoch: 2, 40 / 50] loss: 0.0011482633417472243\n",
            "[Epoch: 2, 50 / 50] loss: 0.0009696446359157562\n",
            "[Epoch: 3, 10 / 50] loss: 0.0009332102490589023\n",
            "[Epoch: 3, 20 / 50] loss: 0.0008242821204476058\n",
            "[Epoch: 3, 30 / 50] loss: 0.0007756857085041702\n",
            "[Epoch: 3, 40 / 50] loss: 0.0007823125924915075\n",
            "[Epoch: 3, 50 / 50] loss: 0.0007685055024921894\n",
            "[Epoch: 4, 10 / 50] loss: 0.0006791244959458709\n",
            "[Epoch: 4, 20 / 50] loss: 0.0006832994986325502\n",
            "[Epoch: 4, 30 / 50] loss: 0.00067442178260535\n",
            "[Epoch: 4, 40 / 50] loss: 0.0005562218721024692\n",
            "[Epoch: 4, 50 / 50] loss: 0.0005940626724623144\n",
            "[Epoch: 5, 10 / 50] loss: 0.0005481321131810546\n",
            "[Epoch: 5, 20 / 50] loss: 0.0005457325023598969\n",
            "[Epoch: 5, 30 / 50] loss: 0.0005063904100097716\n",
            "[Epoch: 5, 40 / 50] loss: 0.0005049261380918324\n",
            "[Epoch: 5, 50 / 50] loss: 0.0005442624678835273\n",
            "[Epoch: 6, 10 / 50] loss: 0.0004807944060303271\n",
            "[Epoch: 6, 20 / 50] loss: 0.00046490266686305404\n",
            "[Epoch: 6, 30 / 50] loss: 0.00048557278933003545\n",
            "[Epoch: 6, 40 / 50] loss: 0.0004864379297941923\n",
            "[Epoch: 6, 50 / 50] loss: 0.0004297411360312253\n",
            "[Epoch: 7, 10 / 50] loss: 0.00043095427099615335\n",
            "[Epoch: 7, 20 / 50] loss: 0.0004293261736165732\n",
            "[Epoch: 7, 30 / 50] loss: 0.0003897497954312712\n",
            "[Epoch: 7, 40 / 50] loss: 0.0004108275461476296\n",
            "[Epoch: 7, 50 / 50] loss: 0.0004108487337362021\n",
            "[Epoch: 8, 10 / 50] loss: 0.0004267060721758753\n",
            "[Epoch: 8, 20 / 50] loss: 0.000356805365299806\n",
            "[Epoch: 8, 30 / 50] loss: 0.0003907323407474905\n",
            "[Epoch: 8, 40 / 50] loss: 0.00039176340214908123\n",
            "[Epoch: 8, 50 / 50] loss: 0.0003580916963983327\n",
            "[Epoch: 9, 10 / 50] loss: 0.0003411010548006743\n",
            "[Epoch: 9, 20 / 50] loss: 0.000331646268023178\n",
            "[Epoch: 9, 30 / 50] loss: 0.0003380152629688382\n",
            "[Epoch: 9, 40 / 50] loss: 0.0003708487784024328\n",
            "[Epoch: 9, 50 / 50] loss: 0.0003555544826667756\n",
            "[Epoch: 10, 10 / 50] loss: 0.00034554224112071097\n",
            "[Epoch: 10, 20 / 50] loss: 0.00029845963581465185\n",
            "[Epoch: 10, 30 / 50] loss: 0.0002976667892653495\n",
            "[Epoch: 10, 40 / 50] loss: 0.00034598330967128277\n",
            "[Epoch: 10, 50 / 50] loss: 0.0003087139630224556\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deosJjfKpBqV",
        "colab_type": "code",
        "outputId": "5e75be56-edac-4061-e581-15d83d2187ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#check the model predictions of a random images after the model has been trained \n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "model = model.eval()\n",
        "\n",
        "images, digits = dataiter.next()\n",
        "imshow(images[0])\n",
        "images = images.to(device)\n",
        "output = model(images)\n",
        "_, predicted = torch.max(output, 1)\n",
        "\n",
        "print('Predicted:' , predicted[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEX4gaAIPxDUfwBgvIctqnZUQgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Predicted: tensor(2, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq0bqlccipA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function logic to run test loop with the test data\n",
        "def test():\n",
        "  model.eval()\n",
        "  \n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, digits = data\n",
        "      images = images.to(device)\n",
        "      digits = digits.to(device)\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += digits.size(0)\n",
        "      correct += (predicted == digits).sum().item()\n",
        "\n",
        "  print(f\"Accuracy of the model is {100 * correct / total}\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiVxB6mgkP1S",
        "colab_type": "code",
        "outputId": "481635a3-a44d-4953-cf2e-51eaedf2e528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#run function to see accuracy of the model on the unknown test data, be sure to train the model before!\n",
        "\n",
        "test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model is 98.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCR51FbdmdDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#If you want to save the model, simply replace the PATH variable with where you want to download it\n",
        "\n",
        "#PATH = \"\"\n",
        "\n",
        "#torch.save(model, PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}